{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a6935d0-4b6a-49cc-be74-7424aca6efce",
   "metadata": {},
   "source": [
    "Visual Crowd Preview Pipeline: Source localization on an Atlas with Beamformer\n",
    "==============================================================================\n",
    "\n",
    "Authors: Tasneem Ezzedine (te2207@nyu.edu), Hadi Zaatiti (hz3752@nyu.edu), Osama Abdullah (oa22@nyu.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf7528-8f38-4ae4-9cc6-b0fad94ae530",
   "metadata": {},
   "source": [
    "Experiment description\n",
    "----------------------\n",
    "\n",
    "[Link to experiment code](https://github.com/hzaatiti-NYU/meg-pipeline/blob/5ac461e002d1db916f57384f61e262060b9e2658/experiments/psychtoolbox/visual_crowding_preview)\n",
    "\n",
    "Contact for this experiment:\n",
    "\n",
    "Tasnim Ezzedin te2207@nyu.edu\n",
    "\n",
    "\n",
    "Description of the experiment:\n",
    "\n",
    "This experiment examines the crowding (the spacing between the letters within each word) and preview effects in the Arabic language, utilizing three distinct crowding values: 0, -75, and -125. Within the experiment, some values are attributed to the crowding effect as a label, respectively: 1 for -125, 2 for -75, and 3 for 0. These values are used in the naming of the images as well as in the final output of the .mat file. Within the .mat file, a column appears containing the number corresponding to the level of crowding (1, 2, or 3).\n",
    "For example, SET1_conn_0_cwdg_1_1.jpg, SET1_conn_0_cwdg_2_1.jpg, etc.\n",
    "Due to the nature of the arabic language being written in cursive, it has a varity of connections between letters. In the naming of the images, the 'conn' refers to the connectivity of the letters. For example, if a word has only two letters that are connected and a crowding level of 1 (i.e. -125) the name would be SET1_conn_2_cwdg_1_1.jpg.\n",
    "The stimuli are made of 300 different arabic words. SET1 has a different combination of crowding values assigned to the words than SET2, however, both have the same words.\n",
    "\n",
    "In this paradigm, participants are instructed to focus on a fixation point on the screen. Words will be presented either to the left or right of the fixation point, and participants will be required to look at the presented word when cued by the fixation point turning green. When a saccade is detected, the target word is displayed. \n",
    "The stimuli were presented as either valid or invalid, with the invalid stimulus being a flipped version of the valid one.\n",
    "After that, the participant has to decide weather or not the word displayed is the same your they saw during the trial by answering the question 'Is this the last word you saw?'.\n",
    "The study employs magnetoencephalography (MEG) and eye-tracking techniques to record brain activity.\n",
    "\n",
    "The trigger channels in MEG are as follows: \n",
    "\n",
    "trigger channel 224: beginn of the overall experiment.\n",
    "trigger channel 225: each display of the fixation point.\n",
    "trigger channel 226: display of the preview image.\n",
    "trigger channel 227: display of the cue (fixation point turns green).\n",
    "trigger channel 228: saccade detection.\n",
    "trigger channel 229: display of the target image.\n",
    "trigger channel 230: display of the question image. \n",
    "\n",
    "Each trigger appears only once in each trial, except trigger channel 225, which appears each time the fixation point is presented. For example, if a fixation is not detected, channels 225 is triggered again until a fixation is detected. \n",
    "Triggers 227, 228, 229 should appear almost at the same time.\n",
    "\n",
    "The .mat file outputs a table with relevant information about the trials, such as the crowding level of each word that was displayed, weather or not it was valid or invalid, number of connections of the letters, question answers, etc.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ab8f39-066c-44ce-ada9-82452d5a2ffb",
   "metadata": {},
   "source": [
    "Importing data\n",
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e59f87180330d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "disp('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd5e26-c60f-430a-b7d9-d84d6114ff88",
   "metadata": {},
   "source": [
    "Trial definition and computing ERP in sensor space\n",
    "--------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c3fa6e-0784-4dd5-8552-a2dbb436525b",
   "metadata": {},
   "source": [
    "Using an Atlas headmodel for Beamformer\n",
    "---------------------------------------\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MATLAB Kernel",
   "language": "matlab",
   "name": "jupyter_matlab_kernel"
  },
  "language_info": {
   "file_extension": ".m",
   "mimetype": "text/x-matlab",
   "name": "matlab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
